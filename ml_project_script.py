# -*- coding: utf-8 -*-
"""ml_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G5PnrdXkyh79JdQIGPWC8AfhJaQXDPvg
"""


import os
import joblib
import numpy as np
import pandas as pd
import seaborn as sns
import plotly.express as px
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix, roc_curve, auc)


api_token = {"username": "leylaeminova",
             "key": "1208531f4079d9b739761ed6f33dceb1"}

from kaggle.api.kaggle_api_extended import KaggleApi  # noqa: E402


def fetch_disease_dataset(dataset_slug, destination_dir='./', unzip=True):

    os.environ['KAGGLE_USERNAME'] = 'leylaeminova'
    os.environ['KAGGLE_KEY'] = '1208531f4079d9b739761ed6f33dceb1'

    api = KaggleApi()
    api.authenticate()

    try:
        api.dataset_download_files(
            dataset_slug, path=destination_dir, unzip=unzip)

        files = os.listdir(destination_dir)

        return files

    except Exception as e:
        print(f"Error downloading dataset: {str(e)}")
        return []


dataset_slug = 'mansoordaku/ckdisease'
destination_directory = './disease_dataset'

downloaded_files = fetch_disease_dataset(dataset_slug, destination_directory)

if downloaded_files:
    print(f"Download successful. Files: {downloaded_files}")
else:
    print("Download failed.")

df = pd.read_csv('./disease_dataset/kidney_disease.csv')
df.info()

df.su.value_counts()

df.head(10)

df.shape

df.isna().sum()

df['age'] = df['age'].fillna(df['age'].mean())
df.drop(['id', 'sg', 'su'], axis=1, inplace=True)

df.info()

df = df.applymap(lambda x: x.strip() if isinstance(x, str)
                 else x)  # removing unnecessary tab chars


def drop_columns_with_nulls(dataset, threshold=50):

    # Identify columns with more than the specified threshold of null values
    columns_to_drop = df.columns[df.isnull().sum() > threshold]

    # Drop the identified columns
    df_dropped = df.drop(columns=columns_to_drop)

    return df_dropped


df = drop_columns_with_nulls(df)


def fill_nulls_with_mode(dataset):

    df_filled = df.apply(lambda col: col.fillna(col.mode()[0]))

    return df_filled


df = fill_nulls_with_mode(df)

df.info()


def visualize_numeric_features(dataset):
    plt.figure(figsize=(20, 15))
    plotnumber = 1
    num_cols = dataset.select_dtypes(include=['float64', 'int64'])
    for column in num_cols:
        if plotnumber <= 14:
            plt.subplot(3, 5, plotnumber)
            sns.histplot(df[column], kde=True)
            plt.xlabel(column)

        plotnumber += 1

    plt.tight_layout()
    plt.show()


visualize_numeric_features(df)

cat_cols = df.select_dtypes(include=['object']).columns.tolist()


def visualize_cat_cols(dataset):
    fig, axes = plt.subplots(3, 3, figsize=(20, 5 * 3))

    for i, column in enumerate(cat_cols):
        ax = axes[i // 3, i % 3]
        sns.countplot(dataset, x=column, palette='rocket', ax=ax)
        ax.set_title(column)
        ax.set_xlabel(column)
        ax.set_ylabel('Count')

    plt.tight_layout()
    plt.show()


visualize_cat_cols(df)

num_cols = df.select_dtypes(include=['float64', 'int64'])
fig = px.box(df, y=num_cols.columns,
             title='Box Plots for detecting outliers',
             labels={'variable': 'Numerical Columns', 'value': 'Values'},
             template='plotly_white')
fig.show()

df.classification.value_counts()

plt.figure(figsize=(15, 8))

sns.heatmap(df.corr(numeric_only=True), annot=True,
            linewidths=2, linecolor='lightgrey')
plt.show()

age_bins = [18, 30, 40, 50, 60, 70, 80, 90, 100]
age_labels = ['18-30', '30-40', '40-50',
              '50-60', '60-70', '70-80', '80-90', '90-100']

# Create a new column 'age_group' based on age bins
df_age = df.copy()
df_age['age_group'] = pd.cut(
    df_age['age'], bins=age_bins, labels=age_labels, right=False)

# Plot the distribution
plt.figure(figsize=(10, 6))
sns.countplot(x='age_group', hue='classification',
              data=df_age, palette='viridis')
plt.title('Chronic Kidney Disease Distribution According to Age Groups')
plt.xlabel('Age Groups')
plt.ylabel('Count')
plt.show()

df.info()

cat_cols

le = LabelEncoder()

for col in cat_cols:
    df[col] = le.fit_transform(df[col])

df.info()

X = df.drop('classification', axis=1)
y = df['classification']

# Commented out IPython magic to ensure Python compatibility.
# %%time
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.4, random_state=42)
pipe_rf = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", RandomForestClassifier())
])
param_grid = {
    "clf__n_estimators": [100, 500, 1000],
    "clf__max_depth": [1, 5, 10, 25],
    "clf__max_features": [0.1, 0.2, 0.3],
}

rf_gs = GridSearchCV(pipe_rf, param_grid=param_grid,
                     cv=3, n_jobs=-1, verbose=1000)
rf_gs.fit(X_train, y_train)
#

rf_gs.score(X_train, y_train)
y_pred_rf = rf_gs.predict(X_test)

joblib.dump(rf_gs, "Random_Forest_model.joblib")

rf_gs.best_params_


def evaluate_model(y_pred, y_test):
    accuracy = accuracy_score(y_test, y_pred)
    print(classification_report(y_test, y_pred))
    print(confusion_matrix(y_test, y_pred))
    print(f"Model accuracy: {accuracy:.4f}")
    # print(classification_report)


evaluate_model(y_pred_rf, y_test)

# Commented out IPython magic to ensure Python compatibility.
# %%time
pipe_lr = Pipeline([
    ("scaler", StandardScaler()),
    ("logistic", LogisticRegression())
])
param_grid_lr = {"logistic__C": np.logspace(-2, 2, 5)}

lr_gs = GridSearchCV(pipe_lr, param_grid=param_grid_lr, cv=3, n_jobs=-1)
lr_gs.fit(X_train, y_train)


joblib.dump(lr_gs, "Logistic_Regression_model.joblib")

y_pred_lr = lr_gs.predict(X_test)

evaluate_model(y_pred_lr, y_test)

fpr1, tpr1, _ = roc_curve(y_test, lr_gs.predict_proba(X_test)[:, 1])
roc_auc1 = auc(fpr1, tpr1)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr1, tpr1, color='darkorange', lw=2,
         label=f'ROC curve (AUC = {roc_auc1:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Classifier 1')
plt.legend()
plt.show()

fpr1, tpr1, _ = roc_curve(y_test, rf_gs.predict_proba(X_test)[:, 1])
roc_auc1 = auc(fpr1, tpr1)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr1, tpr1, color='darkorange', lw=2,
         label=f'ROC curve (AUC = {roc_auc1:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Classifier 2')
plt.legend()
plt.show()


def get_user_input(feature_names):
    features = []

    for feature_name in feature_names:
        while True:
            try:
                value = float(input(f'Enter value for {feature_name}: '))
                break
            except ValueError:
                print('Invalid input. Please enter a numeric value.')

        features.append(value)

    return np.array(features).reshape(1, -1)


def make_prediction(model_filename, user_input):
    model = joblib.load(model_filename)
    prediction = model.predict(user_input)[0]
    proba = model.predict_proba(user_input).max()
    return prediction, proba


def main():
    features = ['age', 'blood pressure', 'albumin',
                'pus cellc cumps', 'bacteria', 'blood glucose rand',
                'blood urea', 'serum creatinine', 'hypertension',
                'diabetes mellitus', 'caronory artery disease',
                'appetite', 'pedal edema', 'anemia']

    user_input = get_user_input(features)
    prediction, proba = make_prediction(
        "Logistic_Regression_model.joblib", user_input)
    print(
        f"Your test result is {'positive' if prediction == 1 else 'negative'}.")
    print(f"The certanity of prediction: {proba*100:.2f}%")
