# -*- coding: utf-8 -*-
"""ml_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G5PnrdXkyh79JdQIGPWC8AfhJaQXDPvg
"""

# pip install kaggle

import joblib
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import pandas as pd
import numpy as np
import os


api_token = {"username": "leylaeminova",
             "key": "1208531f4079d9b739761ed6f33dceb1"}

# with open('/root/.kaggle/kaggle.json', 'w') as file:
#     json.dump(api_token, file)


from kaggle.api.kaggle_api_extended import KaggleApi  # noqa: E402


def fetch_disease_dataset(dataset_slug, destination_dir='./', unzip=True):

    os.environ['KAGGLE_USERNAME'] = 'leylaeminova'
    os.environ['KAGGLE_KEY'] = '1208531f4079d9b739761ed6f33dceb1'

    api = KaggleApi()
    api.authenticate()

    try:
        api.dataset_download_files(
            dataset_slug, path=destination_dir, unzip=unzip)

        files = os.listdir(destination_dir)

        return files

    except Exception as e:
        print(f"Error downloading dataset: {str(e)}")
        return []


dataset_slug = 'mansoordaku/ckdisease'
destination_directory = './disease_dataset'

downloaded_files = fetch_disease_dataset(dataset_slug, destination_directory)

if downloaded_files:
    print(f"Download successful. Files: {downloaded_files}")
else:
    print("Download failed.")

df = pd.read_csv('./disease_dataset/kidney_disease.csv')
df.info()

df.head(10)

df.shape

df['age'] = df['age'].fillna(df['age'].mean())
df.drop(['id', 'sg'], axis=1, inplace=True)

df.info()

df = df.applymap(lambda x: x.strip() if isinstance(x, str)
                 else x)  # removing unnecessary tab chars


def drop_columns_with_nulls(dataset, threshold=50):

    # Identify columns with more than the specified threshold of null values
    columns_to_drop = df.columns[df.isnull().sum() > threshold]

    # Drop the identified columns
    df_dropped = df.drop(columns=columns_to_drop)

    return df_dropped


df = drop_columns_with_nulls(df)


def fill_nulls_with_mode(dataset):

    df_filled = df.apply(lambda col: col.fillna(col.mode()[0]))

    return df_filled


df = fill_nulls_with_mode(df)

df.info()


def visualize_numeric_features(dataset):
    plt.figure(figsize=(20, 15))
    plotnumber = 1
    num_cols = dataset.select_dtypes(include=['float64', 'int64'])
    for column in num_cols:
        if plotnumber <= 14:
            plt.subplot(3, 5, plotnumber)
            sns.histplot(df[column], kde=True)
            plt.xlabel(column)

        plotnumber += 1

    plt.tight_layout()
    plt.show()


# visualize_numeric_features(df)

cat_cols = df.select_dtypes(include=['object'])


def visualize_cat_cols(dataset):

    plt.figure(figsize=(20, 15))
    plotnumber = 1

    for column in cat_cols:
        if plotnumber <= 11:
            plt.subplot(3, 4, plotnumber)
            sns.countplot(dataset[column], palette='rocket')
            plt.xlabel(column)

        plotnumber += 1

    plt.tight_layout()
    plt.show()


num_cols = df.select_dtypes(include=['float64', 'int64'])
fig = px.box(df, y=num_cols.columns,
             title='Box Plots for detecting outliers',
             labels={'variable': 'Numerical Columns', 'value': 'Values'},
             template='plotly_white')
# fig.show()

df.classification.value_counts()

plt.figure(figsize=(15, 8))

sns.heatmap(df.corr(numeric_only=True), annot=True,
            linewidths=2, linecolor='lightgrey')
plt.show()

age_bins = [18, 30, 40, 50, 60, 70, 80, 90, 100]
age_labels = ['18-30', '30-40', '40-50',
              '50-60', '60-70', '70-80', '80-90', '90-100']

# Create a new column 'age_group' based on age bins
df_age = df.copy()
df_age['age_group'] = pd.cut(
    df_age['age'], bins=age_bins, labels=age_labels, right=False)

# Plot the distribution
plt.figure(figsize=(10, 6))
sns.countplot(x='age_group', hue='classification',
              data=df_age, palette='viridis')
plt.title('Chronic Kidney Disease Distribution According to Age Groups')
plt.xlabel('Age Groups')
plt.ylabel('Count')
plt.show()

df.info()

le = LabelEncoder()

for col in cat_cols:
    df[col] = le.fit_transform(df[col])

df.info()

X = df.drop('classification', axis=1)
y = df['classification']


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42)
X_train.info()
pipe_rf = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", RandomForestClassifier())
])
param_grid = {
    "clf__n_estimators": [100, 500, 1000],
    "clf__max_depth": [1, 5, 10, 25],
    "clf__max_features": [0.1, 0.2, 0.3],
}

rf_gs = GridSearchCV(pipe_rf, param_grid=param_grid,
                     cv=3, n_jobs=-1, verbose=1000)
rf_gs.fit(X_train, y_train)

rf_gs.score(X_train, y_train)
y_pred_rf = rf_gs.predict(X_test)

joblib.dump(rf_gs, "Logistic_Regression_model.joblib")

rf_gs.best_params_


def evaluate_model(y_pred, y_test):
    accuracy = accuracy_score(y_test, y_pred)
    print(classification_report(y_test, y_pred))
    print(f"Model accuracy: {accuracy:.4f}")
    # print(classification_report)


evaluate_model(y_pred_rf, y_test)

pipe_lr = Pipeline([
    ("scaler", StandardScaler()),
    ("logistic", LogisticRegression())
])
param_grid_lr = {"logistic__C": np.logspace(-2, 2, 5)}

lr_gs = GridSearchCV(pipe_lr, param_grid=param_grid_lr, cv=3, n_jobs=-1)
lr_gs.fit(X_train, y_train)

joblib.dump(lr_gs, "Logistic_Regression_model.joblib")

y_pred_lr = lr_gs.predict(X_test)

evaluate_model(y_pred_lr, y_test)


def get_user_input(feature_names):
    features = []

    for feature_name in feature_names:
        while True:
            try:
                value = float(input(f'Enter value for {feature_name}: '))
                break
            except ValueError:
                print('Invalid input. Please enter a numeric value.')

        features.append(value)

    return np.array(features).reshape(1, -1)


def make_prediction(model_filename, user_input):
    model = joblib.load(model_filename)
    prediction = model.predict(user_input)[0]
    proba = model.predict_proba(user_input).max()
    return prediction, proba


def main():
    features = ['age', 'blood pressure', 'albumin',
                'sugar', 'pus cellc cumps', 'bacteria', 'blood glucose rand',
                'blood urea', 'serum creatinine', 'hypertension',
                'diabetes mellitus',
                'caronory artery disease', 'appetite', 'pedal edema', 'anemia']

    user_input = get_user_input(features)
    prediction, proba = make_prediction(
        "Logistic_Regression_model.joblib", user_input)
    print(
        f"Your test result is {'positive' if prediction == 1 else 'negative'}.")
    print(f"The certanity of prediction: {proba*100:.2f}%")


if __name__ == "__main__":
    main()
